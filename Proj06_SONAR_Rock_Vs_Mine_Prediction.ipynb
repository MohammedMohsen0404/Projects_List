{"metadata":{"colab":{"provenance":[],"mount_file_id":"1o4rUDMG9Jm1F8-ot88lFuwwMsSt74ZoC","authorship_tag":"ABX9TyPgC1N/jOdvhGPb/NoXrZUn"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4014983,"sourceType":"datasetVersion","datasetId":2379740}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mohammedmohsen0404/sonar-rock-vs-mine-prediction?scriptVersionId=188649914\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"---\n**<center><h1>SONAR Rock Vs Mine Prediction</h1></center>**\n<center><h3>Part of 100 Days 100 ML Projects Challenge</h3></center>\n\n---\n\n","metadata":{"id":"FV6HgOrgIYhP"}},{"cell_type":"markdown","source":"\nThe SONAR Rock Vs Mine Prediction falls under **Classication Machine Learning Problem**. The project aims to develop a machine learning model capable of accurately distinguishing between metal cylinders(mines) and rocks based on SONAR return data.","metadata":{"id":"VyjgmelyXwab"}},{"cell_type":"markdown","source":"# **Import Libraries and Data**\n---","metadata":{"id":"S5RpSXVvLQ3M"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","metadata":{"id":"AVjHdndFLa-N","execution":{"iopub.status.busy":"2024-07-17T07:33:52.703356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nimport xgboost as xgb\nfrom sklearn.metrics import classification_report , f1_score","metadata":{"id":"O3CKXeJDtKYC","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/rock-vs-mine-prediction-machine-learning/Sonar dataset.csv', header = None)\ndf=data.copy()","metadata":{"id":"IOqKU5ekMIDz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Take a look at the data**\n---","metadata":{"id":"-OpQBQ1tX9Qk"}},{"cell_type":"code","source":"df.head()","metadata":{"id":"VNvE7AzMMktP","outputId":"9b97249d-420c-4c6c-9414-ea3327f8197c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"id":"w23_oAv0YNXy","outputId":"25e0c57b-52c3-4d46-f19f-bd25f80a78aa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"id":"h6ZsyWhXZq4J","outputId":"85db325d-3848-43be-8bba-368d105d1518","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"id":"KcHS9m6nYEEp","outputId":"47a1a278-6dc6-496a-f624-89c6e251ab68","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[:,60].value_counts()","metadata":{"id":"JtCtNPETZ0va","outputId":"44f7ea3b-4fa1-4232-9432-a117e52f041f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Exploratory Data Analysis**\n---","metadata":{"id":"_uUSezcKa4ns"}},{"cell_type":"code","source":"plt.hist (df.drop(df.columns[60], axis = 1))\nplt.show()","metadata":{"id":"5I6rfGiyamAp","outputId":"aa8b2c1c-7bc7-4890-887a-15760bb3ff91","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Univariate Analysis**","metadata":{"id":"7soj2PhmSAsO"}},{"cell_type":"code","source":"numerical_data = data.select_dtypes(include='number')\nnumerical_data.hist(figsize=(10, 8),color = 'b')\nplt.tight_layout()\nplt.show()","metadata":{"id":"OkABiRuHSAUv","outputId":"f982cdc4-2683-4318-8d4d-ee5b9637d8cf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 8))\nsns.boxplot(numerical_data)\nplt.show()","metadata":{"id":"SUarHG5HThFN","outputId":"02d20814-05fb-458e-bde2-51baf6955d5d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_data = data.select_dtypes(include='object')\nfor column in categorical_data.columns:\n    sns.countplot(data=categorical_data, x=column, palette=\"Set1\")\n    plt.title(f\"Countplot of {column}\")\n    plt.show()","metadata":{"id":"8pzy7T3LRmW-","outputId":"a609872b-23f6-438a-cb8b-9cd14ce7fc84","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.pie(df.iloc[:,60].value_counts(), labels=['R','M'], autopct='%1.1f%%')\nplt.show()","metadata":{"id":"c3dr04ai2goT","outputId":"3f388f17-3fcc-48a9-eb4e-04c3236af107","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Multivariate Analysis**","metadata":{"id":"0QRg-06Rb_eE"}},{"cell_type":"code","source":"sns.pairplot(data.select_dtypes(include='number'))\nplt.show()","metadata":{"id":"8PTK9nHEckhY","outputId":"6aeda043-4281-47da-af64-c651fe1f2641","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(numerical_data.corr(), annot=True, cmap='coolwarm')\nplt.show()","metadata":{"id":"Vm8rAbD4dtpT","outputId":"94052de9-6bf7-411c-87cc-d642716f7cf1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Cleaning**\n---","metadata":{"id":"zvjMyN4Ssfdm"}},{"cell_type":"markdown","source":"**Handling Duplicate Rows**","metadata":{"id":"0zwQ6PI6nlXY"}},{"cell_type":"code","source":"# Check for duplicate rows\nduplicate_rows = df.duplicated()\n# Count of duplicate rows\nprint(f\"Number of duplicate rows: {duplicate_rows.sum()}\")","metadata":{"id":"4S1160R-bv2R","outputId":"26fef478-760c-430b-f795-77739abfa084","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Handling Missing Data**","metadata":{"id":"G2f_IWCuxT7I"}},{"cell_type":"code","source":"total = data.isnull().sum().sort_values(ascending=False)\npercent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(10)","metadata":{"id":"Kpw9CP0dki25","outputId":"a6267fbe-54ea-4dbf-d5f8-83da89388f23","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total = data.isnull().sum().sum()\nprint('Total Null values =' ,total)","metadata":{"id":"PMBflmf8kwNj","outputId":"ee0fb72a-81dc-4411-cda4-229585d616c2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Preprocesing**\n----","metadata":{"id":"wfmPeRh0hvuv"}},{"cell_type":"markdown","source":"It's important to conduct preprocessing steps separately on train, test sets to avoid data leakage, which can lead to overly optimistic performance estimates.\nso let's split the data","metadata":{"id":"Pbaj30qqijPX"}},{"cell_type":"markdown","source":"**Data Splitting**","metadata":{"id":"pbDqRSOOxYoL"}},{"cell_type":"code","source":"X = df.drop(df.columns[60], axis = 1)\ny = df.iloc[:,60]","metadata":{"id":"dpVhHzEujw-K","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.3,random_state=101)","metadata":{"id":"4_beQxRPjY84","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Encoding Categorical Variables**","metadata":{"id":"AnuESEfHney1"}},{"cell_type":"code","source":"y_train = y_train.apply(lambda x : 0 if x == 'R' else 1)\ny_test = y_test.apply(lambda x : 0 if x == 'R' else 1)","metadata":{"id":"Xsx5gjiAnK32","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Dealing with Outliers**","metadata":{"id":"i0TPJY7zsqIK"}},{"cell_type":"code","source":"# Boxplot\nplt.figure(figsize=(20, 10))\nplt.boxplot(X_train)\nplt.title('Boxplot for Outlier Detection')\nplt.show()","metadata":{"id":"2FbToSzRo0z0","outputId":"18004196-ce05-44f1-e870-9e8d16a2256b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Q1 = X_train.quantile(0.25)\nQ3 = X_train.quantile(0.75)\nIQR = Q3 - Q1\noutliers = X_train[((X_train < (Q1 - 1.5 * IQR)) | (X_train > (Q3 + 1.5 * IQR))).any(axis=1)]\n\nprint(\"Outliers using IQR method:\")\nprint(outliers)","metadata":{"id":"hzMSp0kIpsAj","outputId":"341e1f43-7818-4ad8-a68f-516e603cdc61","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.log(X_train + 1)\nX_test = np.log(X_test + 1)","metadata":{"id":"yA_8cDJGqfz9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Normalization**","metadata":{"id":"bMjB5c0Bsuja"}},{"cell_type":"code","source":"scalar = StandardScaler()\nX_train = scalar.fit_transform(X_train)\nX_test = scalar.transform(X_test)","metadata":{"id":"2_HErXt_rgDm","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Modeling**","metadata":{"id":"2enC__gns32s"}},{"cell_type":"code","source":"classifiers = [\n    ('Logistic Regression', LogisticRegression(random_state=42)),\n    ('Random Forest', RandomForestClassifier(random_state=42)),\n    ('Gradient Boosting', GradientBoostingClassifier(random_state=42)),\n    ('K-Nearest Neighbors', KNeighborsClassifier()),\n    ('Support Vector Machine', SVC(random_state=42)),\n    ('xgboost', xgb.XGBClassifier(tree_method=\"hist\")),\n]","metadata":{"id":"grHvMMgxtJ7-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for clf_name, clf in classifiers:\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    f1 = f1_score(y_test, y_pred, average='weighted')  # Using weighted average for multi-class classification\n    print(f'{clf_name}: F1 Score = {f1:.2f}')\n    print(f'{clf_name} Classification Report:\\n{classification_report(y_test, y_pred)}')\n    print('---------------------------------------------------')","metadata":{"id":"1uYaxCOcvelz","outputId":"272d1337-9fa5-45ea-8939-c52ba36c519b","trusted":true},"execution_count":null,"outputs":[]}]}
